{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_curve\n",
    "from sklearn.metrics import rand_score, adjusted_rand_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cm(\n",
    "    tp: int,\n",
    "    fp: int,\n",
    "    fn: int,\n",
    "    tn: int,\n",
    ") -> dict:\n",
    "    \"\"\"Evaluate the performance of a model on a dataset using confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "        tp (int): true positives\n",
    "        fp (int): false positives\n",
    "        fn (int): false negatives\n",
    "        tn (int): true negatives\n",
    "        \n",
    "    Returns:\n",
    "        dict: dictionary containing the following metrics:\n",
    "            - accuracy\n",
    "            - precision\n",
    "            - recall\n",
    "            - f1\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    res['accuracy'] = (tp + tn) / (tp + fp + fn + tn)\n",
    "    res['precision'] = tp / (tp + fp)\n",
    "    res['recall'] = tp / (tp + fn)\n",
    "    res['f1'] = (2 * tp) / (2 * tp + fp + fn)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(preds: list, labels: list):\n",
    "    \"\"\"Evaluate the performance of a model on a dataset.\n",
    "    \n",
    "    Args:\n",
    "        preds (list): list of predicted values\n",
    "        labels (list): list of true values\n",
    "    \n",
    "    Returns:\n",
    "        dict: dictionary containing the following metrics:\n",
    "            - accuracy\n",
    "            - precision\n",
    "            - recall\n",
    "            - f1\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(preds, labels).ravel()\n",
    "    res = evaluate_cm(tp, fp, fn, tn)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(labels, preds)\n",
    "    res['fpr'] = fpr\n",
    "    res['tpr'] = tpr\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clusters(preds: list, labels: list):\n",
    "    \"\"\"Evaluate the performance of clustering algorithms.\n",
    "    \n",
    "    Args:\n",
    "        preds (list): list of predicted values\n",
    "        labels (list): list of true values\n",
    "    \n",
    "    Returns:\n",
    "        dict: dictionary containing the following metrics:\n",
    "            - rand_score\n",
    "            - adjusted_rand_score\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    res['rand_score'] = rand_score(preds, labels)\n",
    "    res['adjusted_rand_score'] = adjusted_rand_score(preds, labels)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_results(results: list[dict]) -> dict:\n",
    "    \"\"\"Calculate the average of a list of results from evaluate().\n",
    "    \n",
    "    Args:\n",
    "        results (list[dict]): list of results from evaluate()\n",
    "        \n",
    "    Returns:\n",
    "        dict: dictionary containing the following metrics:\n",
    "            - accuracy\n",
    "            - precision\n",
    "            - recall\n",
    "            - f1\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for key in results[0]:\n",
    "        if key in [\n",
    "            'accuracy',\n",
    "            'precision',\n",
    "            'recall', \n",
    "            'f1',\n",
    "            'rand_score',\n",
    "            'adjusted_rand_score',\n",
    "        ]:\n",
    "            # calculate average\n",
    "            res[key] = sum([r[key] for r in results]) / len(results)\n",
    "            \n",
    "            # round to 2 decimals\n",
    "            res[key] = round(res[key], 2)\n",
    "        elif key in ['fpr', 'tpr']:\n",
    "            # calculate average\n",
    "            res[key] = np.mean([r[key] for r in results], axis=0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_fpr_tpr(\n",
    "    fpr: float,\n",
    "    tpr: float,\n",
    "    path: str,\n",
    "):\n",
    "    \"\"\"Make a plot of the ROC curve.\n",
    "    \n",
    "    Args:\n",
    "        fpr (list): false positive rate\n",
    "        tpr (list): true positive rate\n",
    "        path (str): path to save the plot\n",
    "    \"\"\"\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(results: dict, path: str):\n",
    "    \"\"\"Make a plot of the ROC curve.\n",
    "    \n",
    "    Args:\n",
    "        results (list[dict]): dictionary containing the results metrics.\n",
    "        path: path to save the plot.\n",
    "    \"\"\"\n",
    "    make_plot_fpr_tpr(results['fpr'], results['tpr'], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cluster_df = cluster_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cluster_df = cluster_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cluster_df = cluster_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results_df = results_df.append(\n",
      "/tmp/ipykernel_13482/871465744.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  cluster_df = cluster_df.append(\n"
     ]
    }
   ],
   "source": [
    "deep_nets = [\n",
    "    'resnet18_pt',\n",
    "]\n",
    "drp_exps = [\n",
    "    'drp_multi_not_pt',\n",
    "    'drp_multi_pt',\n",
    "    'drp_single_not_pt',\n",
    "    'drp_single_pt',\n",
    "    'drp_single_aux_not_pt',\n",
    "    'drp_single_aux_pt',\n",
    "]\n",
    "kviews_exps = [\n",
    "    'kviews_17',\n",
    "    'kviews_19',\n",
    "    'kviews_25',\n",
    "]\n",
    "kmeans_exp = [\n",
    "    'kmeans',\n",
    "]\n",
    "exps = drp_exps + kviews_exps + kmeans_exp\n",
    "\n",
    "results_df = pd.DataFrame(\n",
    "    data=None,\n",
    "    columns=['model', 'accuracy', 'precision', 'recall', 'f1'],\n",
    ")\n",
    "cluster_df = pd.DataFrame(\n",
    "    data=None,\n",
    "    columns=['model', 'rand_score', 'adjusted_rand_score'],\n",
    ")\n",
    "\n",
    "base_path = Path('./results')\n",
    "for exp in exps:\n",
    "    res = []\n",
    "    cluster_res = []\n",
    "    path = base_path / exp\n",
    "    if exp in drp_exps:\n",
    "        # aggregate results from results.json files\n",
    "        folders = glob(str(path / '*'))\n",
    "        for folder in folders:\n",
    "            with open(Path(folder) / 'results.json') as fin:\n",
    "                data = json.load(fin)\n",
    "            res.append(evaluate(data['pred_labels'], data['gt_labels']))\n",
    "                \n",
    "    elif exp in kviews_exps:\n",
    "        if exp == 'kviews_17' or exp == 'kviews_19':\n",
    "            # kviews 17 and 19 has all results in one csv file\n",
    "            data = pd.read_csv(Path(path) / 'results.csv')\n",
    "            preds = data['predict'].tolist()\n",
    "            labels = data['label'].tolist()\n",
    "            \n",
    "            # each trial has 300 samples, of 6 trials\n",
    "            for i in range(6):\n",
    "                res.append(evaluate(\n",
    "                    preds[i::6],\n",
    "                    labels[i::6],\n",
    "                ))\n",
    "                cluster_res.append(evaluate_clusters(\n",
    "                    preds[i::6],\n",
    "                    labels[i::6],\n",
    "                ))\n",
    "                \n",
    "        else:\n",
    "            # aggregate results from results.csv files\n",
    "            folders = glob(str(path / '*'))\n",
    "            res = []\n",
    "            for folder in folders:\n",
    "                data = pd.read_csv(Path(folder) / 'results.csv')\n",
    "                res.append(evaluate(\n",
    "                    data['predict'].tolist(),\n",
    "                    data['label'].tolist(),\n",
    "                ))\n",
    "                cluster_res.append(evaluate_clusters(\n",
    "                    data['predict'].tolist(),\n",
    "                    data['label'].tolist(),\n",
    "                ))\n",
    "        \n",
    "    elif exp in kmeans_exp:\n",
    "        # aggregate results from results.csv files\n",
    "        folders = glob(str(path / '*'))\n",
    "        res = []\n",
    "        for folder in folders:\n",
    "            data = pd.read_csv(Path(folder) / 'results.csv')\n",
    "            res.append(evaluate(\n",
    "                data['predict'].tolist(),\n",
    "                data['label'].tolist(),\n",
    "            ))\n",
    "            cluster_res.append(evaluate_clusters(\n",
    "                data['predict'].tolist(),\n",
    "                data['label'].tolist(),\n",
    "            ))\n",
    "\n",
    "    # average results\n",
    "    avg_res = None\n",
    "    if res != []:\n",
    "        avg_res = average_results(res)\n",
    "        avg_res['model'] = exp\n",
    "        results_df = results_df.append(\n",
    "            pd.Series(\n",
    "                data=avg_res,\n",
    "                index=['model', 'accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
    "            ),\n",
    "            ignore_index=True,\n",
    "        )\n",
    "        \n",
    "        # make plots\n",
    "        plot_path = path.parent / 'roc_plots' / '{0}_roc.png'.format(exp)\n",
    "        plot_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        make_plot(avg_res, str(plot_path))\n",
    "        \n",
    "    if cluster_res != []:\n",
    "        avg_res = average_results(cluster_res)\n",
    "        avg_res['model'] = exp\n",
    "        cluster_df = cluster_df.append(\n",
    "            pd.Series(\n",
    "                data=avg_res,\n",
    "                index=['model', 'rand_score', 'adjusted_rand_score'],\n",
    "            ),\n",
    "            ignore_index=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13482/2058295068.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  results_df.to_latex(base_path / 'results.tex')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drp_multi_not_pt</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drp_multi_pt</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drp_single_not_pt</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drp_single_pt</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drp_single_aux_not_pt</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drp_single_aux_pt</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kviews_17</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kviews_19</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kviews_25</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   model accuracy precision recall    f1 roc_auc\n",
       "0       drp_multi_not_pt     0.87      0.89   0.92  0.91    0.86\n",
       "1           drp_multi_pt     0.88      0.89   0.93  0.91    0.87\n",
       "2      drp_single_not_pt     0.88       0.9   0.94  0.92    0.88\n",
       "3          drp_single_pt     0.88       0.9   0.93  0.91    0.87\n",
       "4  drp_single_aux_not_pt     0.87      0.89   0.92   0.9    0.86\n",
       "5      drp_single_aux_pt     0.89       0.9   0.94  0.92    0.89\n",
       "6              kviews_17     0.62      0.79   0.59  0.68    0.62\n",
       "7              kviews_19     0.62       0.8   0.59  0.68    0.62\n",
       "8              kviews_25     0.52      0.71   0.51  0.59    0.52\n",
       "9                 kmeans     0.47      0.07   0.35  0.11    0.47"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.to_csv(base_path / 'results.csv')\n",
    "results_df.to_latex(base_path / 'results.tex')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13482/2168607566.py:2: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  cluster_df.to_latex(base_path / 'cluster_results.tex')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>rand_score</th>\n",
       "      <th>adjusted_rand_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kviews_17</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kviews_19</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kviews_25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model rand_score adjusted_rand_score\n",
       "0  kviews_17       0.53                0.06\n",
       "1  kviews_19       0.53                0.06\n",
       "2  kviews_25        0.5                -0.0\n",
       "3     kmeans        0.5                 0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_df.to_csv(base_path / 'cluster_results.csv')\n",
    "cluster_df.to_latex(base_path / 'cluster_results.tex')\n",
    "cluster_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('cuticulus')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db4fa47e449f269b6e53f5916110b6e3a48885985b5ef8238ccf2bd8c2aa5784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
